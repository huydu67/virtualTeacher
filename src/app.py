import streamlit as st
import torch
import os
import sys
import sounddevice as sd
import numpy as np
import wave
import time
from transformers import AutoModel, AutoTokenizer

# Get the project root
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from utils import app_utils

# Database connection
DB_CONFIG = "dbname=virtualTeacher user=postgres password=password host=localhost"
device = "cuda" if torch.cuda.is_available() else "cpu"

DATA_FOLDER = "data"
os.makedirs(DATA_FOLDER, exist_ok=True)

# Load PhoBERT model & tokenizer
phobert = AutoModel.from_pretrained("vinai/phobert-large").to(device)
tokenizer = AutoTokenizer.from_pretrained("vinai/phobert-large")
#
# # Reflection Categories
# reflection_categories = [
#     "Quáº£n lÃ½ lá»›p há»c",
#     "Táº¡o Ä‘á»™ng lá»±c cho há»c sinh",
#     "Giáº£i quyáº¿t xung Ä‘á»™t",
#     "PhÆ°Æ¡ng phÃ¡p giáº£ng dáº¡y",
#     "CÃ¡ch Ä‘Ã¡nh giÃ¡ há»c sinh",
#     "Äá»™ng lá»±c há»c táº­p"
# ]


# Streamlit Chat UI

if "recording" not in st.session_state:
    st.session_state.recording = False
if "audio_file" not in st.session_state:
    st.session_state.audio_file = None

st.set_page_config(page_title="AI Personal Assistant")
st.title("ğŸ§‘â€ğŸ« AI Teacher Chatbot")

# Chat history for UI
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "awaiting_response" not in st.session_state:
    st.session_state.awaiting_response = False  # Track if waiting for user response

if not st.session_state.recording:
    if st.button("ğŸ¤ Start Recording"):
        st.session_state.recording = True
        st.session_state.audio_file = None
        st.rerun()
else:
    if st.button("ğŸ›‘ Stop Recording"):
        st.session_state.recording = False
        st.rerun()

if st.session_state.recording:
    st.write("ğŸ™ï¸ Recording... Speak now!")

uploaded_file = st.file_uploader("Upload a voice file (.mp3 or .wav)", type=["mp3", "wav"])

if uploaded_file is not None:
    file_path = os.path.join(DATA_FOLDER, uploaded_file.name)
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    st.session_state.audio_file = file_path
    transcribed_text = app_utils.transcribe_audio(file_path)
    if transcribed_text:
        st.write(f"ğŸ“ Transcribed Text: {transcribed_text}")
        st.session_state.chat_history.append({"role": "user", "content": transcribed_text})

if not st.session_state.recording and st.session_state.audio_file:
    transcribed_text = app_utils.transcribe_audio(st.session_state.audio_file)
    if transcribed_text:
        st.write(f"ğŸ“ Transcribed Text: {transcribed_text}")
        st.session_state.chat_history.append({"role": "user", "content": transcribed_text})
        st.session_state.audio_file = None

# Display chat history
st.write("### ğŸ“© Lá»‹ch sá»­ há»™i thoáº¡i")
for message in st.session_state.chat_history:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# User text input
reflection_input = st.text_input("Nháº­p váº¥n Ä‘á» giáº£ng dáº¡y cá»§a báº¡n:", key="reflection_input") if not st.session_state.awaiting_response else None

if reflection_input:
    user_id = 5  # Default user ID

    # Generate embedding for the user reflection
    user_embedding = app_utils.get_phobert_embedding(reflection_input)

    # Search for a similar past reflection using PGVector
    similar_reflection, reflection_id = app_utils.search_similar_reflection(user_embedding)

    if similar_reflection:
        # Retrieve stored AI-generated self-reflection question
        ai_question = app_utils.get_stored_ai_question(reflection_id)
        st.session_state.chat_history.append(
            {"role": "assistant", "content": f"âœ… **CÃ¢u há»i tÆ°Æ¡ng tá»± Ä‘Ã£ cÃ³ trong há»‡ thá»‘ng:** {similar_reflection}"})
        st.session_state.chat_history.append(
            {"role": "assistant", "content": f"ğŸ¤” **AI Reflection Prompt:** {ai_question}"})
    else:
        # Store new reflection if no match is found
        app_utils.store_new_reflection(user_id, reflection_input)
        st.session_state.chat_history.append({"role": "assistant",
                                              "content": "âœ… **Pháº£n xáº¡ cá»§a báº¡n Ä‘Ã£ Ä‘Æ°á»£c lÆ°u trá»¯.** HÃ£y tiáº¿p tá»¥c lÃ m viá»‡c vá»›i pháº£n xáº¡ nÃ y trong tÆ°Æ¡ng lai."})

    # Mark that the chatbot is awaiting a response from the user
    st.session_state.awaiting_response = True
    reflection_input = ""  # Clear input after submission


# Handle user response input (Only enabled after a reflection question is shown)
if st.session_state.awaiting_response:
    response_input = st.text_input("Nháº­p váº¥n Ä‘á» giáº£ng dáº¡y cá»§a báº¡n:", key="response_input")

    if response_input:
        # Generate embedding for user response
        response_embedding = app_utils.get_phobert_embedding(response_input)

        # Search `chat_history` for the most relevant AI-generated feedback
        similar_feedback = app_utils.search_chat_history_feedback(response_embedding)

        # Store user response in chat history
        st.session_state.chat_history.append({"role": "user", "content": response_input})

        if similar_feedback:
            st.session_state.chat_history.append(
                {"role": "assistant", "content": f"ğŸ“Œ **AI Feedback:** {similar_feedback}"})
        else:
            st.session_state.chat_history.append(
                {"role": "assistant", "content": "KhÃ´ng cÃ³ pháº£n há»“i phÃ¹ há»£p trong há»‡ thá»‘ng. HÃ£y thá»­ láº¡i sau!"})

        # Reset the flag to allow new reflections to be entered
        st.session_state.awaiting_response = False





